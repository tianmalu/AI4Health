{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d377ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading labels: 100%|██████████| 19101/19101 [00:00<00:00, 3819384.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "label_dict = {}\n",
    "with open(\"../ComParE2017_Cold_4students/lab/ComParE2017_Cold.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "    rows = list(reader)\n",
    "    for row in tqdm(rows, desc=\"Loading labels\"):\n",
    "        label_dict[row[\"file_name\"]] = row[\"Cold (upper respiratory tract infection)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31512250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def search_in_labels(filename, label_dict):\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    if \"_logmel\" in base_name:\n",
    "        base_name = base_name.replace(\"_logmel\", \"\")\n",
    "    if \"_flipped\" in base_name:\n",
    "        base_name = base_name.replace(\"_flipped\", \"\")\n",
    "    \n",
    "    parts = base_name.split(\"_\")\n",
    "    if len(parts) >= 2:\n",
    "        audio_filename = f\"{parts[0]}_{parts[1]}.wav\"\n",
    "    else:\n",
    "        audio_filename = f\"{base_name}.wav\"\n",
    "    \n",
    "    return label_dict.get(audio_filename, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229cbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class AttentionMIL(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, num_windows, feature_dim)\n",
    "        attn_weights = self.attention(x)  # (batch, num_windows, 1)\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)  # normalize\n",
    "        weighted_x = x * attn_weights  # (batch, num_windows, feature_dim)\n",
    "        return weighted_x.sum(dim=1), attn_weights  # 同时返回注意力权重\n",
    "\n",
    "class SpectrogramSequenceClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 cnn_out_dim=512, \n",
    "                 sequence_model='transformer',  # 'transformer', 'lstm', 'attention'\n",
    "                 hidden_dim=256,\n",
    "                 num_heads=8,\n",
    "                 num_layers=2,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN Encoder for each window\n",
    "        self.cnn_encoder = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),  # 输出 (512, 4, 4)\n",
    "            \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(2048, cnn_out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.sequence_model_type = sequence_model\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 序列模型选择\n",
    "        if sequence_model == 'transformer':\n",
    "            self.pos_encoding = PositionalEncoding(cnn_out_dim, dropout)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=cnn_out_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=hidden_dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.sequence_model = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "            self.global_pool = nn.AdaptiveAvgPool1d(1)  # 全局平均池化\n",
    "            \n",
    "        elif sequence_model == 'lstm':\n",
    "            self.sequence_model = nn.LSTM(\n",
    "                input_size=cnn_out_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                num_layers=num_layers,\n",
    "                dropout=dropout if num_layers > 1 else 0,\n",
    "                batch_first=True,\n",
    "                bidirectional=True\n",
    "            )\n",
    "            lstm_out_dim = hidden_dim * 2  # 双向LSTM\n",
    "            \n",
    "        elif sequence_model == 'attention':\n",
    "            self.sequence_model = SelfAttention(cnn_out_dim, hidden_dim, num_heads, dropout)\n",
    "\n",
    "        elif sequence_model == 'attention_mil':\n",
    "            # Attention-based MIL聚合\n",
    "            self.sequence_model = AttentionMIL(cnn_out_dim, hidden_dim)\n",
    "            classifier_input_dim = cnn_out_dim\n",
    "\n",
    "        elif sequence_model == 'hybrid':\n",
    "            # 混合方法：先Transformer再MIL\n",
    "            self.pos_encoding = PositionalEncoding(cnn_out_dim, dropout)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=cnn_out_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=hidden_dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "            self.mil_attention = AttentionMIL(cnn_out_dim, hidden_dim)\n",
    "            classifier_input_dim = cnn_out_dim\n",
    "            \n",
    "        # 分类头\n",
    "        if sequence_model == 'lstm':\n",
    "            classifier_input_dim = lstm_out_dim\n",
    "        else:\n",
    "            classifier_input_dim = cnn_out_dim\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1)  # 二分类\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_windows, C, H, W = x.shape\n",
    "        \n",
    "        # CNN特征提取\n",
    "        x = x.view(-1, C, H, W)\n",
    "        cnn_features = self.cnn_encoder(x)\n",
    "        cnn_features = cnn_features.view(batch_size, num_windows, -1)\n",
    "        \n",
    "        # 初始化attention_weights为None\n",
    "        attention_weights = None\n",
    "        \n",
    "        # 序列建模\n",
    "        if self.sequence_model_type == 'transformer':\n",
    "            x = self.pos_encoding(cnn_features)\n",
    "            x = self.sequence_model(x)\n",
    "            x = x.mean(dim=1)  # 全局平均池化\n",
    "            \n",
    "        elif self.sequence_model_type == 'lstm':\n",
    "            x, _ = self.sequence_model(cnn_features)\n",
    "            x = x[:, -1, :]\n",
    "            \n",
    "        elif self.sequence_model_type == 'attention_mil':\n",
    "            # 使用Attention MIL聚合\n",
    "            x, attention_weights = self.sequence_model(cnn_features)\n",
    "            \n",
    "        elif self.sequence_model_type == 'hybrid':\n",
    "            # 先Transformer处理序列，再MIL聚合\n",
    "            x = self.pos_encoding(cnn_features)\n",
    "            x = self.transformer(x)\n",
    "            x, attention_weights = self.mil_attention(x)\n",
    "        \n",
    "        # 分类\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        # 根据训练状态决定返回值\n",
    "        if self.sequence_model_type == 'attention_mil':\n",
    "            # 如果是Attention MIL，返回注意力权重\n",
    "            return output, attention_weights\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "# 位置编码（用于Transformer）\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1), :].transpose(0, 1)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# 自注意力模块\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=input_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 自注意力\n",
    "        attn_output, attn_weights = self.multihead_attn(x, x, x)\n",
    "        \n",
    "        # 残差连接和层归一化\n",
    "        x = self.norm(x + self.dropout(attn_output))\n",
    "        \n",
    "        # 全局平均池化\n",
    "        x = x.mean(dim=1)  # (batch_size, input_dim)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b521cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class AddGaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def forward(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std + self.mean\n",
    "    \n",
    "class SequenceSpectrogramDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_dict, window_size=128, stride=64, \n",
    "                 max_windows=10, is_training=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_dict = label_dict\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.max_windows = max_windows\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        if is_training:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                AddGaussianNoise(0, 0.02),\n",
    "\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        filename = os.path.basename(image_path)\n",
    "        label = search_in_labels(filename, self.label_dict)\n",
    "        label_num = 1 if label == \"C\" else 0\n",
    "        \n",
    "        # 加载图像\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = self.transform(image)\n",
    "        \n",
    "        _, H, W = image_tensor.shape\n",
    "        assert H == 128, f\"Image height must be 128, but got {H}\"\n",
    "        \n",
    "        # 滑动窗口提取\n",
    "        windows = []\n",
    "        for start in range(0, W - self.window_size + 1, self.stride):\n",
    "            window = image_tensor[:, :, start:start + self.window_size]\n",
    "            windows.append(window)\n",
    "        \n",
    "        # 处理最后一个窗口\n",
    "        if (W - self.window_size) % self.stride != 0:\n",
    "            last_window = image_tensor[:, :, -self.window_size:]\n",
    "            windows.append(last_window)\n",
    "        \n",
    "        # 确保至少有一个窗口\n",
    "        if len(windows) == 0:\n",
    "            pad_width = self.window_size - W\n",
    "            image_padded = F.pad(image_tensor, (0, pad_width), mode='constant', value=0)\n",
    "            window = image_padded[:, :, :self.window_size]\n",
    "            windows.append(window)\n",
    "        \n",
    "        # 限制最大窗口数量\n",
    "        if len(windows) > self.max_windows:\n",
    "            if self.is_training:\n",
    "                # 随机选择\n",
    "                indices = torch.randperm(len(windows))[:self.max_windows]\n",
    "                windows = [windows[i] for i in indices]\n",
    "            else:\n",
    "                # 均匀采样\n",
    "                indices = torch.linspace(0, len(windows)-1, self.max_windows).long()\n",
    "                windows = [windows[i] for i in indices]\n",
    "        \n",
    "        # 如果窗口不足，进行填充\n",
    "        while len(windows) < self.max_windows:\n",
    "            windows.append(windows[-1].clone())  # 复制最后一个窗口\n",
    "        \n",
    "        # 堆叠成序列\n",
    "        windows_tensor = torch.stack(windows)  # (max_windows, 3, 128, 128)\n",
    "        \n",
    "        return windows_tensor, label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e894d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Collecting image paths...\n",
      "🔍 Looking for images in: ../spectrograms_variable_width\\train_files\n",
      "📁 Found 10475 PNG files in train_files\n",
      "🔍 Looking for images in: ../spectrograms_variable_width\\devel_files\n",
      "📁 Found 10607 PNG files in devel_files\n",
      "📋 After filtering out 'flipped' files: 9596 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "data_split = [\"train_files\", \"devel_files\"]\n",
    "img_dir = \"../spectrograms_variable_width\"  \n",
    "\n",
    "def collect_image_paths_devel(split_name):\n",
    "        sub_dir = os.path.join(img_dir, split_name)\n",
    "        print(f\"🔍 Looking for images in: {sub_dir}\")\n",
    "        \n",
    "        if not os.path.exists(sub_dir):\n",
    "            print(f\"❌ Directory does not exist: {sub_dir}\")\n",
    "            return []\n",
    "        \n",
    "        png_files = glob.glob(os.path.join(sub_dir, \"*.png\"))\n",
    "        \n",
    "        filtered_files = [f for f in png_files if \"flipped\" not in os.path.basename(f)]\n",
    "        \n",
    "        print(f\"📁 Found {len(png_files)} PNG files in {split_name}\")\n",
    "        print(f\"📋 After filtering out 'flipped' files: {len(filtered_files)} files\")\n",
    "        \n",
    "        return filtered_files\n",
    "\n",
    "def collect_image_paths(split_name):\n",
    "    sub_dir = os.path.join(img_dir, split_name)\n",
    "    print(f\"🔍 Looking for images in: {sub_dir}\")\n",
    "    \n",
    "    if not os.path.exists(sub_dir):\n",
    "        print(f\"❌ Directory does not exist: {sub_dir}\")\n",
    "        return []\n",
    "    \n",
    "    png_files = glob.glob(os.path.join(sub_dir, \"*.png\"))\n",
    "    print(f\"📁 Found {len(png_files)} PNG files in {split_name}\")\n",
    "    \n",
    "    return png_files\n",
    "\n",
    "print(\"🚀 Collecting image paths...\")\n",
    "train_image_paths = collect_image_paths(\"train_files\")\n",
    "devel_image_paths = collect_image_paths_devel(\"devel_files\")\n",
    "\n",
    "train_dataset = SequenceSpectrogramDataset(\n",
    "    image_paths=train_image_paths,\n",
    "    label_dict=label_dict,\n",
    "    window_size=128,\n",
    "    stride=64,\n",
    "    max_windows=5,\n",
    "    is_training=True\n",
    ")\n",
    "val_dataset = SequenceSpectrogramDataset(\n",
    "    image_paths=devel_image_paths,\n",
    "    label_dict=label_dict,\n",
    "    window_size=128,\n",
    "    stride=64,\n",
    "    max_windows=5, \n",
    "    is_training=False\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,  \n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,  \n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab271fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_sequence_model(model, dataloader, device, criterion):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_windows, batch_labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            batch_windows = batch_windows.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            logits = model(batch_windows).squeeze()\n",
    "            if logits.dim() == 0:\n",
    "                logits = logits.unsqueeze(0)\n",
    "            \n",
    "            # 计算loss\n",
    "            loss = criterion(logits, batch_labels.float())\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "                \n",
    "            preds = (torch.sigmoid(logits) > 0.6).long()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    # 计算平均loss\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "    \n",
    "    # 计算指标\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    uar = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return avg_loss, f1, uar, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5b617ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(2.0))\n",
    "        \n",
    "    def forward(self, logits, labels, attention_weights=None):\n",
    "        # 主要的分类loss\n",
    "        classification_loss = self.bce_loss(logits, labels.float())\n",
    "        \n",
    "        # 注意力正则化loss（鼓励注意力分布的多样性）\n",
    "        if attention_weights is not None:\n",
    "            # 计算注意力熵，鼓励不要过度集中在少数windows\n",
    "            attention_entropy = -(attention_weights * torch.log(attention_weights + 1e-8)).sum(dim=1).mean()\n",
    "            total_loss = classification_loss - self.alpha * attention_entropy\n",
    "        else:\n",
    "            total_loss = classification_loss\n",
    "            \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e7155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 655/655 [00:57<00:00, 11.41it/s, loss=0.8698]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train - Loss: 1.0702, Acc: 0.8148, F1: 0.0000\n",
      "  Val - Loss: 0.8332, F1: 0.0000, UAR: 0.5000\n",
      "  🌟 New best UAR: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 655/655 [00:57<00:00, 11.45it/s, loss=1.3632]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train - Loss: 1.0519, Acc: 0.8149, F1: 0.0271\n",
      "  Val - Loss: 0.8168, F1: 0.1683, UAR: 0.5431\n",
      "  🌟 New best UAR: 0.5431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 655/655 [00:56<00:00, 11.51it/s, loss=0.8785]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train - Loss: 1.0326, Acc: 0.8116, F1: 0.1373\n",
      "  Val - Loss: 0.7855, F1: 0.1699, UAR: 0.5436\n",
      "  🌟 New best UAR: 0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 655/655 [00:57<00:00, 11.49it/s, loss=1.0145]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train - Loss: 1.0009, Acc: 0.8167, F1: 0.2649\n",
      "  Val - Loss: 0.7860, F1: 0.2359, UAR: 0.5729\n",
      "  🌟 New best UAR: 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 655/655 [00:56<00:00, 11.51it/s, loss=0.7162]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train - Loss: 0.9466, Acc: 0.8311, F1: 0.3989\n",
      "  Val - Loss: 0.7870, F1: 0.2486, UAR: 0.5814\n",
      "  🌟 New best UAR: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 655/655 [00:56<00:00, 11.53it/s, loss=0.5947]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train - Loss: 0.8739, Acc: 0.8516, F1: 0.5332\n",
      "  Val - Loss: 0.7957, F1: 0.2568, UAR: 0.5889\n",
      "  🌟 New best UAR: 0.5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 655/655 [00:56<00:00, 11.51it/s, loss=0.5074]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train - Loss: 0.8242, Acc: 0.8564, F1: 0.5804\n",
      "  Val - Loss: 0.8267, F1: 0.2933, UAR: 0.6303\n",
      "  🌟 New best UAR: 0.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 655/655 [00:57<00:00, 11.46it/s, loss=0.7319]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train - Loss: 0.7883, Acc: 0.8624, F1: 0.6042\n",
      "  Val - Loss: 0.8353, F1: 0.2935, UAR: 0.6316\n",
      "  🌟 New best UAR: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 655/655 [00:57<00:00, 11.48it/s, loss=0.6039]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train - Loss: 0.7606, Acc: 0.8618, F1: 0.6130\n",
      "  Val - Loss: 0.9824, F1: 0.2739, UAR: 0.6384\n",
      "  🌟 New best UAR: 0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 655/655 [00:59<00:00, 11.06it/s, loss=0.3813]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train - Loss: 0.7406, Acc: 0.8631, F1: 0.6218\n",
      "  Val - Loss: 0.9685, F1: 0.2814, UAR: 0.6435\n",
      "  🌟 New best UAR: 0.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 655/655 [00:57<00:00, 11.37it/s, loss=0.8488]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n",
      "  Train - Loss: 0.7177, Acc: 0.8666, F1: 0.6372\n",
      "  Val - Loss: 0.8634, F1: 0.2827, UAR: 0.6182\n",
      "  Early stopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 655/655 [00:57<00:00, 11.44it/s, loss=0.3843]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\n",
      "  Train - Loss: 0.7111, Acc: 0.8684, F1: 0.6396\n",
      "  Val - Loss: 0.9733, F1: 0.2842, UAR: 0.6417\n",
      "  Early stopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 655/655 [00:57<00:00, 11.49it/s, loss=0.2157]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\n",
      "  Train - Loss: 0.6890, Acc: 0.8736, F1: 0.6548\n",
      "  Val - Loss: 0.9375, F1: 0.2710, UAR: 0.6178\n",
      "  Early stopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 655/655 [00:57<00:00, 11.48it/s, loss=0.2539]\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\n",
      "  Train - Loss: 0.6848, Acc: 0.8752, F1: 0.6608\n",
      "  Val - Loss: 1.0400, F1: 0.2671, UAR: 0.6236\n",
      "  Early stopping counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 655/655 [00:57<00:00, 11.45it/s, loss=0.2869]\n",
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:\n",
      "  Train - Loss: 0.6586, Acc: 0.8830, F1: 0.6769\n",
      "  Val - Loss: 1.0461, F1: 0.2807, UAR: 0.6416\n",
      "  Early stopping counter: 5/5\n",
      "Early stopping triggered. Stopping training.\n",
      "Training complete! Best UAR: 0.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 选择序列模型类型\n",
    "model = SpectrogramSequenceClassifier(\n",
    "    cnn_out_dim=512,\n",
    "    sequence_model='transformer',  # 'transformer', 'lstm', 'attention'\n",
    "    hidden_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=1,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(4).to(device))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-6, weight_decay=1e-7)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3)\n",
    "\n",
    "# 训练\n",
    "num_epochs = 50\n",
    "best_uar = 0.0\n",
    "patience = 5\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch_windows, batch_labels in progress_bar:\n",
    "        batch_windows = batch_windows.to(device)  # (batch_size, max_windows, 3, 128, 128)\n",
    "        batch_labels = batch_labels.to(device)    # (batch_size,)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        logits = model(batch_windows).squeeze()   # (batch_size,)\n",
    "        if logits.dim() == 0:\n",
    "            logits = logits.unsqueeze(0)\n",
    "            \n",
    "        loss = criterion(logits, batch_labels.float())\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 计算预测\n",
    "        preds = (torch.sigmoid(logits) > 0.6).long()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # 计算指标\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    train_f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    # 验证\n",
    "    avg_loss, f1, val_uar, val_labels, val_preds = evaluate_sequence_model(model, val_loader, device, criterion)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train - Loss: {running_loss/len(train_loader):.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"  Val - Loss: {avg_loss:.4f}, F1: {f1:.4f}, UAR: {val_uar:.4f}\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_uar > best_uar:\n",
    "        best_uar = val_uar\n",
    "        torch.save(model.state_dict(), 'best_sequence_model_2.pth')\n",
    "        print(f\"  🌟 New best UAR: {best_uar:.4f}\")\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"  Early stopping counter: {early_stopping_counter}/{patience}\")\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step(val_uar)\n",
    "\n",
    "print(f\"Training complete! Best UAR: {best_uar:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8c2f0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SpectrogramSequenceClassifier(\n",
    "    cnn_out_dim=256,\n",
    "    sequence_model='attention_mil',  # 使用MIL\n",
    "    hidden_dim=128,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# 使用MIL loss\n",
    "criterion = MILLoss(alpha=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c580c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with Attention MIL...\n",
      "Model: attention_mil\n",
      "Parameters: 688,322\n",
      "\n",
      "================================================================================\n",
      "Epoch [1/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/655 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 655/655 [06:01<00:00,  1.81it/s, loss=0.3734, avg_loss=0.7100]\n",
      "Validation Epoch 1: 100%|██████████| 300/300 [01:18<00:00,  3.82it/s, val_loss=0.4355, avg_val_loss=0.5082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.7100, Acc: 0.8167, F1: 0.0476, UAR: 0.5107\n",
      "Validation - Loss: 0.5082, Acc: 0.8909, F1: 0.1089, UAR: 0.5258\n",
      "Class Recalls - Healthy: 0.9884, Cold: 0.0633\n",
      "Attention weights - Mean: [0.2754279  0.19137117 0.18316384 0.17952251 0.17051463]\n",
      "Attention weights - Std:  [0.04251278 0.02831747 0.02631738 0.02507317 0.02371163]\n",
      "Most important window: 0 (weight: 0.2754)\n",
      "🌟 New best UAR: 0.5258, model saved!\n",
      "Best UAR so far: 0.5258\n",
      "\n",
      "================================================================================\n",
      "Epoch [2/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 655/655 [06:10<00:00,  1.77it/s, loss=0.7667, avg_loss=0.5829]\n",
      "Validation Epoch 2: 100%|██████████| 300/300 [01:22<00:00,  3.65it/s, val_loss=0.4979, avg_val_loss=0.5048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.5829, Acc: 0.8559, F1: 0.5247, UAR: 0.6911\n",
      "Validation - Loss: 0.5048, Acc: 0.8877, F1: 0.0739, UAR: 0.5149\n",
      "Class Recalls - Healthy: 0.9872, Cold: 0.0425\n",
      "Attention weights - Mean: [0.25964236 0.19059387 0.18453002 0.18350157 0.18173222]\n",
      "Attention weights - Std:  [0.05666114 0.03416167 0.03050242 0.02907554 0.02840365]\n",
      "Most important window: 0 (weight: 0.2596)\n",
      "⏳ No improvement for 1/5 epochs\n",
      "Best UAR so far: 0.5258\n",
      "\n",
      "================================================================================\n",
      "Epoch [3/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 655/655 [06:13<00:00,  1.75it/s, loss=0.2464, avg_loss=0.4892]\n",
      "Validation Epoch 3: 100%|██████████| 300/300 [01:23<00:00,  3.61it/s, val_loss=0.5071, avg_val_loss=0.5028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.4892, Acc: 0.8754, F1: 0.6394, UAR: 0.7676\n",
      "Validation - Loss: 0.5028, Acc: 0.8926, F1: 0.1472, UAR: 0.5377\n",
      "Class Recalls - Healthy: 0.9873, Cold: 0.0880\n",
      "Attention weights - Mean: [0.23608373 0.19401203 0.1900369  0.189817   0.1900504 ]\n",
      "Attention weights - Std:  [0.04206767 0.02924171 0.02587952 0.02447437 0.02393272]\n",
      "Most important window: 0 (weight: 0.2361)\n",
      "🌟 New best UAR: 0.5377, model saved!\n",
      "Best UAR so far: 0.5377\n",
      "\n",
      "================================================================================\n",
      "Epoch [4/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 655/655 [06:23<00:00,  1.71it/s, loss=0.2563, avg_loss=0.4530]\n",
      "Validation Epoch 4: 100%|██████████| 300/300 [01:23<00:00,  3.58it/s, val_loss=0.5796, avg_val_loss=0.5187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.4530, Acc: 0.8836, F1: 0.6635, UAR: 0.7816\n",
      "Validation - Loss: 0.5187, Acc: 0.8559, F1: 0.2138, UAR: 0.5604\n",
      "Class Recalls - Healthy: 0.9348, Cold: 0.1860\n",
      "Attention weights - Mean: [0.2153361  0.19616434 0.19484645 0.19573659 0.19791654]\n",
      "Attention weights - Std:  [0.02811105 0.02314117 0.01997692 0.01869156 0.01816249]\n",
      "Most important window: 0 (weight: 0.2153)\n",
      "🌟 New best UAR: 0.5604, model saved!\n",
      "Best UAR so far: 0.5604\n",
      "\n",
      "================================================================================\n",
      "Epoch [5/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 655/655 [06:23<00:00,  1.71it/s, loss=0.1432, avg_loss=0.4290]\n",
      "Validation Epoch 5: 100%|██████████| 300/300 [01:22<00:00,  3.64it/s, val_loss=0.5376, avg_val_loss=0.5078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.4290, Acc: 0.8891, F1: 0.6790, UAR: 0.7903\n",
      "Validation - Loss: 0.5078, Acc: 0.8778, F1: 0.1894, UAR: 0.5503\n",
      "Class Recalls - Healthy: 0.9652, Cold: 0.1355\n",
      "Attention weights - Mean: [0.21706188 0.1956438  0.19458053 0.19534472 0.19736908]\n",
      "Attention weights - Std:  [0.03263332 0.02534659 0.02171865 0.02037849 0.01994068]\n",
      "Most important window: 0 (weight: 0.2171)\n",
      "⏳ No improvement for 1/5 epochs\n",
      "Best UAR so far: 0.5604\n",
      "\n",
      "================================================================================\n",
      "Epoch [6/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 655/655 [06:19<00:00,  1.73it/s, loss=0.3550, avg_loss=0.4073]\n",
      "Validation Epoch 6: 100%|██████████| 300/300 [01:21<00:00,  3.66it/s, val_loss=0.4949, avg_val_loss=0.4946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.4073, Acc: 0.8970, F1: 0.7009, UAR: 0.8022\n",
      "Validation - Loss: 0.4946, Acc: 0.8916, F1: 0.1950, UAR: 0.5533\n",
      "Class Recalls - Healthy: 0.9819, Cold: 0.1246\n",
      "Attention weights - Mean: [0.22216052 0.19499806 0.19321266 0.19393492 0.1956938 ]\n",
      "Attention weights - Std:  [0.04474369 0.03279345 0.02850872 0.02708638 0.02699584]\n",
      "Most important window: 0 (weight: 0.2222)\n",
      "⏳ No improvement for 2/5 epochs\n",
      "Best UAR so far: 0.5604\n",
      "\n",
      "================================================================================\n",
      "Epoch [7/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 655/655 [06:20<00:00,  1.72it/s, loss=0.5948, avg_loss=0.3973]\n",
      "Validation Epoch 7: 100%|██████████| 300/300 [01:22<00:00,  3.64it/s, val_loss=0.5361, avg_val_loss=0.4921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.3973, Acc: 0.8972, F1: 0.7019, UAR: 0.8031\n",
      "Validation - Loss: 0.4921, Acc: 0.8716, F1: 0.2761, UAR: 0.5897\n",
      "Class Recalls - Healthy: 0.9469, Cold: 0.2324\n",
      "Attention weights - Mean: [0.22090124 0.19436733 0.19320996 0.19451559 0.19700588]\n",
      "Attention weights - Std:  [0.04239969 0.02986862 0.02616129 0.02487054 0.02461621]\n",
      "Most important window: 0 (weight: 0.2209)\n",
      "🌟 New best UAR: 0.5897, model saved!\n",
      "Best UAR so far: 0.5897\n",
      "\n",
      "================================================================================\n",
      "Epoch [8/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 655/655 [06:17<00:00,  1.73it/s, loss=0.0976, avg_loss=0.3842]\n",
      "Validation Epoch 8: 100%|██████████| 300/300 [01:21<00:00,  3.66it/s, val_loss=0.4979, avg_val_loss=0.4894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [8] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.3842, Acc: 0.9018, F1: 0.7147, UAR: 0.8101\n",
      "Validation - Loss: 0.4894, Acc: 0.8831, F1: 0.2618, UAR: 0.5804\n",
      "Class Recalls - Healthy: 0.9639, Cold: 0.1968\n",
      "Attention weights - Mean: [0.2111472  0.19748296 0.19537196 0.19643593 0.19956195]\n",
      "Attention weights - Std:  [0.04013909 0.03106999 0.02692309 0.02550613 0.02502733]\n",
      "Most important window: 0 (weight: 0.2111)\n",
      "⏳ No improvement for 1/5 epochs\n",
      "Best UAR so far: 0.5897\n",
      "\n",
      "================================================================================\n",
      "Epoch [9/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 655/655 [06:18<00:00,  1.73it/s, loss=0.6740, avg_loss=0.3707]\n",
      "Validation Epoch 9: 100%|██████████| 300/300 [01:22<00:00,  3.63it/s, val_loss=0.4917, avg_val_loss=0.5272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [9] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.3707, Acc: 0.9051, F1: 0.7268, UAR: 0.8187\n",
      "Validation - Loss: 0.5272, Acc: 0.8929, F1: 0.2474, UAR: 0.5727\n",
      "Class Recalls - Healthy: 0.9783, Cold: 0.1672\n",
      "Attention weights - Mean: [0.2167499  0.19705632 0.19399977 0.19475359 0.19744042]\n",
      "Attention weights - Std:  [0.04897913 0.03652412 0.03155878 0.03004584 0.02981487]\n",
      "Most important window: 0 (weight: 0.2167)\n",
      "⏳ No improvement for 2/5 epochs\n",
      "Best UAR so far: 0.5897\n",
      "\n",
      "================================================================================\n",
      "Epoch [10/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 655/655 [06:21<00:00,  1.72it/s, loss=0.0619, avg_loss=0.3644]\n",
      "Validation Epoch 10: 100%|██████████| 300/300 [01:22<00:00,  3.65it/s, val_loss=0.4797, avg_val_loss=0.5297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [10] Summary:\n",
      "────────────────────────────────────────────────────────────\n",
      "Training   - Loss: 0.3644, Acc: 0.9021, F1: 0.7232, UAR: 0.8203\n",
      "Validation - Loss: 0.5297, Acc: 0.8985, F1: 0.1589, UAR: 0.5423\n",
      "Class Recalls - Healthy: 0.9936, Cold: 0.0910\n",
      "Attention weights - Mean: [0.2114687  0.19630946 0.19562002 0.1968387  0.19976309]\n",
      "Attention weights - Std:  [0.0486172  0.03781758 0.03272303 0.03127244 0.03145121]\n",
      "Most important window: 0 (weight: 0.2115)\n",
      "⏳ No improvement for 3/5 epochs\n",
      "Best UAR so far: 0.5897\n",
      "\n",
      "================================================================================\n",
      "Epoch [11/50]\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11:  27%|██▋       | 178/655 [01:40<04:30,  1.76it/s, loss=0.5250, avg_loss=0.3563]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     49\u001b[0m     preds \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 50\u001b[0m     all_train_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     51\u001b[0m     all_train_labels\u001b[38;5;241m.\u001b[39mextend(batch_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     53\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "num_epochs = 50\n",
    "best_uar = 0.0\n",
    "patience = 5\n",
    "early_stopping_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# 记录训练历史\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "training_uars = []\n",
    "validation_uars = []\n",
    "\n",
    "print(\"Starting training with Attention MIL...\")\n",
    "print(f\"Model: {model.sequence_model_type}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # =================== 训练阶段 ===================\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_train_preds, all_train_labels = [], []\n",
    "    \n",
    "    print(f'\\n{\"=\"*80}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'{\"=\"*80}')\n",
    "    \n",
    "    train_progress = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch_idx, (batch_windows, batch_labels) in enumerate(train_progress):\n",
    "        batch_windows = batch_windows.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 修复：正确解包模型输出\n",
    "        logits, _ = model(batch_windows)  # 忽略attention_weights\n",
    "        logits = logits.squeeze()\n",
    "        if logits.dim() == 0:\n",
    "            logits = logits.unsqueeze(0)\n",
    "            \n",
    "        loss = criterion(logits, batch_labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 计算训练预测\n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "            all_train_preds.extend(preds.cpu().numpy())\n",
    "            all_train_labels.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_progress.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{running_loss/(batch_idx+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    # 计算训练指标\n",
    "    epoch_train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, zero_division=0)\n",
    "    train_uar = recall_score(all_train_labels, all_train_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    training_losses.append(epoch_train_loss)\n",
    "    training_uars.append(train_uar)\n",
    "    \n",
    "    # =================== 验证阶段 ===================\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    all_val_preds, all_val_labels = [], []\n",
    "    all_attention_weights = []\n",
    "    \n",
    "    val_progress = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_windows, batch_labels) in enumerate(val_progress):\n",
    "            batch_windows = batch_windows.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            # 修复：正确解包模型输出\n",
    "            logits, attention_weights = model(batch_windows)\n",
    "            \n",
    "            # 保存attention weights（如果存在）\n",
    "            if attention_weights is not None:\n",
    "                all_attention_weights.append(attention_weights.cpu())\n",
    "                \n",
    "            logits = logits.squeeze()\n",
    "            if logits.dim() == 0:\n",
    "                logits = logits.unsqueeze(0)\n",
    "            \n",
    "            loss = criterion(logits, batch_labels.float())\n",
    "            val_running_loss += loss.item()\n",
    "            \n",
    "            # 计算预测\n",
    "            preds = (torch.sigmoid(logits) > 0.5).long()\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_labels.extend(batch_labels.cpu().numpy())\n",
    "            \n",
    "            val_progress.set_postfix({\n",
    "                'val_loss': f'{loss.item():.4f}',\n",
    "                'avg_val_loss': f'{val_running_loss/(batch_idx+1):.4f}'\n",
    "            })\n",
    "    \n",
    "    # 计算验证指标\n",
    "    epoch_val_loss = val_running_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, zero_division=0)\n",
    "    val_uar = recall_score(all_val_labels, all_val_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    validation_losses.append(epoch_val_loss)\n",
    "    validation_uars.append(val_uar)\n",
    "    \n",
    "    # =================== 打印结果 ===================\n",
    "    print(f\"\\nEpoch [{epoch+1}] Summary:\")\n",
    "    print(f\"{'─'*60}\")\n",
    "    print(f\"Training   - Loss: {epoch_train_loss:.4f}, Acc: {train_accuracy:.4f}, F1: {train_f1:.4f}, UAR: {train_uar:.4f}\")\n",
    "    print(f\"Validation - Loss: {epoch_val_loss:.4f}, Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}, UAR: {val_uar:.4f}\")\n",
    "    \n",
    "    # 显示类别召回率\n",
    "    if len(set(all_val_labels)) > 1 and len(set(all_val_preds)) > 1:\n",
    "        class_recalls = recall_score(all_val_labels, all_val_preds, average=None, zero_division=0)\n",
    "        print(f\"Class Recalls - Healthy: {class_recalls[0]:.4f}, Cold: {class_recalls[1]:.4f}\")\n",
    "    \n",
    "    # 显示注意力权重统计（如果有的话）\n",
    "    if all_attention_weights:\n",
    "        attention_concat = torch.cat(all_attention_weights, dim=0)  # (total_samples, num_windows, 1)\n",
    "        attention_mean = attention_concat.mean(dim=0).squeeze()  # (num_windows,)\n",
    "        attention_std = attention_concat.std(dim=0).squeeze()   # (num_windows,)\n",
    "        \n",
    "        print(f\"Attention weights - Mean: {attention_mean.numpy()}\")\n",
    "        print(f\"Attention weights - Std:  {attention_std.numpy()}\")\n",
    "        \n",
    "        # 找出最重要的窗口\n",
    "        most_important_window = torch.argmax(attention_mean).item()\n",
    "        print(f\"Most important window: {most_important_window} (weight: {attention_mean[most_important_window]:.4f})\")\n",
    "    \n",
    "    # =================== 保存最佳模型 ===================\n",
    "    if val_uar > best_uar:\n",
    "        best_uar = val_uar\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        torch.save(model.state_dict(), 'best_attention_mil_model.pth')\n",
    "        print(f\"🌟 New best UAR: {best_uar:.4f}, model saved!\")\n",
    "        \n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"⏳ No improvement for {early_stopping_counter}/{patience} epochs\")\n",
    "        \n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"❌ Early stopping triggered after {patience} epochs without improvement\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Best UAR so far: {best_uar:.4f}\")\n",
    "\n",
    "# =================== 训练完成 ===================\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🎉 Training completed in {total_time:.2f} minutes!\")\n",
    "print(f\"🏆 Best Validation UAR: {best_uar:.4f}\")\n",
    "print(f\"📁 Best model saved as: 'best_attention_mil_model.pth'\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# =================== 保存训练历史 ===================\n",
    "training_history = {\n",
    "    'training_losses': training_losses,\n",
    "    'validation_losses': validation_losses,\n",
    "    'training_uars': training_uars,\n",
    "    'validation_uars': validation_uars,\n",
    "    'best_uar': best_uar,\n",
    "    'total_epochs': epoch + 1,\n",
    "    'early_stopped': early_stopping_counter >= patience,\n",
    "    'sequence_model_type': model.sequence_model_type\n",
    "}\n",
    "\n",
    "torch.save(training_history, 'attention_mil_training_history.pth')\n",
    "print(f\"💾 Training history saved to 'attention_mil_training_history.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
