{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dff8dcf",
   "metadata": {},
   "source": [
    "# Sliding Window on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd930a6e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40bf27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19101/19101 [00:00<00:00, 3822482.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "label_dict = {}\n",
    "with open(\"../ComParE2017_Cold_4students/lab/ComParE2017_Cold.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "    rows = list(reader)\n",
    "    for row in tqdm(rows, desc=\"Loading labels\"):\n",
    "        label_dict[row[\"file_name\"]] = row[\"Cold (upper respiratory tract infection)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45c5f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def search_in_labels(filename, label_dict):\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    if \"_logmel\" in base_name:\n",
    "        base_name = base_name.replace(\"_logmel\", \"\")\n",
    "    if \"_flipped\" in base_name:\n",
    "        base_name = base_name.replace(\"_flipped\", \"\")\n",
    "    \n",
    "    parts = base_name.split(\"_\")\n",
    "    if len(parts) >= 2:\n",
    "        audio_filename = f\"{parts[0]}_{parts[1]}.wav\"\n",
    "    else:\n",
    "        audio_filename = f\"{base_name}.wav\"\n",
    "    \n",
    "    return label_dict.get(audio_filename, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f7686",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90949ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_dict, transform=None, window_size=128, stride=64, is_training=False, num_windows=3):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_dict = label_dict\n",
    "        self.is_training = is_training \n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.num_windows = num_windows\n",
    "\n",
    "        self.base_transform = transforms.Compose([\n",
    "            # transforms.RandomAffine(degrees=0, translate=(0.3, 0)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        self.c_train_transform = transforms.Compose([\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.3, 0)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        filename = os.path.basename(image_path)\n",
    "        label = search_in_labels(filename, self.label_dict)\n",
    "        label_num = 1 if label == \"C\" else 0\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.is_training and label == \"C\":\n",
    "            image = self.c_train_transform(image)\n",
    "        elif self.is_training and label == \"NC\":\n",
    "            image = self.base_transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "\n",
    "        _, H, W = image.shape\n",
    "        assert H == 128, f\"Image height must be 128, but got {H}\"\n",
    "\n",
    "        windows = []\n",
    "        for start in range(0, W - self.window_size + 1, self.stride):\n",
    "            window = image[:, :, start:start + self.window_size]\n",
    "            windows.append(window)\n",
    "\n",
    "        if (W - self.window_size) % self.stride != 0:\n",
    "            last_window = image[:, :, -self.window_size:]\n",
    "            windows.append(last_window)\n",
    "\n",
    "        if len(windows) == 0:\n",
    "            pad_width = self.window_size - W\n",
    "            image_padded = F.pad(image, (0, pad_width), mode='constant', value=0)\n",
    "            window = image_padded[:, :, :self.window_size]\n",
    "            windows.append(window)\n",
    "\n",
    "        windows = torch.stack(windows)  # Shape: (num_extracted_windows, 3, 128, 128)\n",
    "\n",
    "        if self.is_training:\n",
    "            # ÈöèÊú∫ÈÄâÊã©ÊåáÂÆöÊï∞ÈáèÁöÑwindows\n",
    "            num_available = windows.shape[0]\n",
    "            \n",
    "            if num_available >= self.num_windows:\n",
    "                rand_indices = torch.randperm(num_available)[:self.num_windows]\n",
    "                selected_windows = windows[rand_indices]  \n",
    "            else:\n",
    "                rand_indices = torch.randint(0, num_available, (self.num_windows,))\n",
    "                selected_windows = windows[rand_indices]  \n",
    "            \n",
    "            labels = torch.full((self.num_windows,), label_num, dtype=torch.long)\n",
    "            \n",
    "            return selected_windows, labels\n",
    "        else:\n",
    "            return windows, label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52f04edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Collecting image paths...\n",
      "üîç Looking for images in: ../spectrograms_variable_width\\train_files\n",
      "üìÅ Found 10475 PNG files in train_files\n",
      "üîç Looking for images in: ../spectrograms_variable_width\\devel_files\n",
      "üìÅ Found 10607 PNG files in devel_files\n",
      "üìã After filtering out 'flipped' files: 9596 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_split = [\"train_files\", \"devel_files\"]\n",
    "img_dir = \"../spectrograms_variable_width\"  \n",
    "\n",
    "def collect_image_paths_devel(split_name):\n",
    "        sub_dir = os.path.join(img_dir, split_name)\n",
    "        print(f\"üîç Looking for images in: {sub_dir}\")\n",
    "        \n",
    "        if not os.path.exists(sub_dir):\n",
    "            print(f\"‚ùå Directory does not exist: {sub_dir}\")\n",
    "            return []\n",
    "        \n",
    "        png_files = glob.glob(os.path.join(sub_dir, \"*.png\"))\n",
    "        \n",
    "        filtered_files = [f for f in png_files if \"flipped\" not in os.path.basename(f)]\n",
    "        \n",
    "        print(f\"üìÅ Found {len(png_files)} PNG files in {split_name}\")\n",
    "        print(f\"üìã After filtering out 'flipped' files: {len(filtered_files)} files\")\n",
    "        \n",
    "        return filtered_files\n",
    "\n",
    "def collect_image_paths(split_name):\n",
    "    sub_dir = os.path.join(img_dir, split_name)\n",
    "    print(f\"üîç Looking for images in: {sub_dir}\")\n",
    "    \n",
    "    if not os.path.exists(sub_dir):\n",
    "        print(f\"‚ùå Directory does not exist: {sub_dir}\")\n",
    "        return []\n",
    "    \n",
    "    png_files = glob.glob(os.path.join(sub_dir, \"*.png\"))\n",
    "    print(f\"üìÅ Found {len(png_files)} PNG files in {split_name}\")\n",
    "    \n",
    "    return png_files\n",
    "\n",
    "print(\"üöÄ Collecting image paths...\")\n",
    "train_image_paths = collect_image_paths(\"train_files\")\n",
    "devel_image_paths = collect_image_paths_devel(\"devel_files\")\n",
    "\n",
    "train_dataset = SpectrogramDataset(\n",
    "    image_paths=train_image_paths,\n",
    "    label_dict=label_dict,\n",
    "    transform=None,\n",
    "    window_size=128,\n",
    "    stride=32,\n",
    "    is_training=True\n",
    ")\n",
    "devel_dataset = SpectrogramDataset(\n",
    "    image_paths=devel_image_paths,\n",
    "    label_dict=label_dict,\n",
    "    transform=None,\n",
    "    window_size=128,\n",
    "    stride=32,\n",
    "    is_training=False\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "devel_loader = DataLoader(\n",
    "    devel_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18875815",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f33c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImprovedCNNBinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_shape=(3, 128, 128), num_classes=1):\n",
    "        super(ImprovedCNNBinaryClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  \n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 512)  \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        x = self.adaptive_pool(x) \n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch, 512*4*4]\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb570ad",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a8c0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ImprovedCNNBinaryClassifier().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(4).to(device))  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-6)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e5e29",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d15cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def eval_with_voting(model, dataset, criterion, device, threshold=0.5, vote_mode='soft'):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in trange(len(dataset), desc=\"Validating\"):\n",
    "            windows, label = dataset[i]  # windows: (N, C, H, W)\n",
    "            label = torch.tensor(label).to(device)\n",
    "\n",
    "            windows = windows.to(device)  # shape: (N, C, H, W)\n",
    "            logits = model(windows).squeeze()  # shape: (N,) or (N,1)\n",
    "\n",
    "            # Á°Æ‰øù logits ÊòØ 1D\n",
    "            if logits.dim() > 1:\n",
    "                logits = logits.squeeze()\n",
    "            if logits.dim() == 0:\n",
    "                logits = logits.unsqueeze(0)\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            # üéØ ÊäïÁ•®\n",
    "            if vote_mode == 'soft':\n",
    "                avg_prob = probs.mean().item()\n",
    "                final_pred = 1 if avg_prob > threshold else 0\n",
    "            else:  # 'hard'\n",
    "                window_preds = (probs > threshold).long()\n",
    "                final_pred = torch.mode(window_preds).values.item()\n",
    "\n",
    "            all_preds.append(final_pred)\n",
    "            all_labels.append(label.item())\n",
    "\n",
    "            # Âπ≥ÂùáÁ™óÂè£ loss\n",
    "            repeated_label = label.repeat(len(logits))\n",
    "            sample_loss = criterion(logits, repeated_label.float()).item()\n",
    "            total_loss += sample_loss\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # üéØ ËøîÂõû loss, accuracy, f1, predictions, labels\n",
    "    return avg_loss, acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96553f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Epoch [1/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:35<00:00,  1.72it/s, loss=0.2920, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 1: 31425\n",
      "Total samples processed in epoch 1: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:05<00:00, 145.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1] Summary:\n",
      "  üìà Training   - Loss: 0.5563, ACCR: 0.8902, F1: 0.7214\n",
      "  üìä Validation - Loss: 1.0710, UAR: 0.5004, F1: 0.0020\n",
      "  üéØ Class Recalls - Healthy: 0.9999, Cold: 0.0010\n",
      "üåü New best UAR: 0.5004, saving model...\n",
      "\n",
      "================================================================================\n",
      "Epoch [2/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:28<00:00,  1.84it/s, loss=0.2382, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 2: 31425\n",
      "Total samples processed in epoch 2: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:04<00:00, 148.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2] Summary:\n",
      "  üìà Training   - Loss: 0.4034, ACCR: 0.9346, F1: 0.8229\n",
      "  üìä Validation - Loss: 0.9679, UAR: 0.5914, F1: 0.2435\n",
      "  üéØ Class Recalls - Healthy: 0.7506, Cold: 0.4322\n",
      "üåü New best UAR: 0.5914, saving model...\n",
      "\n",
      "================================================================================\n",
      "Epoch [3/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:31<00:00,  1.78it/s, loss=0.1884, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 3: 31425\n",
      "Total samples processed in epoch 3: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:04<00:00, 147.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3] Summary:\n",
      "  üìà Training   - Loss: 0.3457, ACCR: 0.9424, F1: 0.8440\n",
      "  üìä Validation - Loss: 0.8355, UAR: 0.5957, F1: 0.2740\n",
      "  üéØ Class Recalls - Healthy: 0.9065, Cold: 0.2849\n",
      "üåü New best UAR: 0.5957, saving model...\n",
      "\n",
      "================================================================================\n",
      "Epoch [4/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:56<00:00,  1.40it/s, loss=0.3578, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 4: 31425\n",
      "Total samples processed in epoch 4: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:06<00:00, 144.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4] Summary:\n",
      "  üìà Training   - Loss: 0.3121, ACCR: 0.9495, F1: 0.8630\n",
      "  üìä Validation - Loss: 1.1764, UAR: 0.5209, F1: 0.0822\n",
      "  üéØ Class Recalls - Healthy: 0.9983, Cold: 0.0435\n",
      "‚è≥ No improvement for 1/4 epochs\n",
      "\n",
      "================================================================================\n",
      "Epoch [5/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:36<00:00,  1.70it/s, loss=0.2914, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 5: 31425\n",
      "Total samples processed in epoch 5: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:17<00:00, 123.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5] Summary:\n",
      "  üìà Training   - Loss: 0.2902, ACCR: 0.9474, F1: 0.8600\n",
      "  üìä Validation - Loss: 2.5997, UAR: 0.5000, F1: 0.0000\n",
      "‚è≥ No improvement for 2/4 epochs\n",
      "\n",
      "================================================================================\n",
      "Epoch [6/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 164/164 [01:47<00:00,  1.52it/s, loss=0.1329, windows=31425, samples=10475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows processed in epoch 6: 31425\n",
      "Total samples processed in epoch 6: 10475\n",
      "Average windows per sample: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9596/9596 [01:06<00:00, 144.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6] Summary:\n",
      "  üìà Training   - Loss: 0.2639, ACCR: 0.9491, F1: 0.8665\n",
      "  üìä Validation - Loss: 1.5688, UAR: 0.5231, F1: 0.0939\n",
      "  üéØ Class Recalls - Healthy: 0.9948, Cold: 0.0514\n",
      "‚è≥ No improvement for 3/4 epochs\n",
      "\n",
      "================================================================================\n",
      "Epoch [7/100]\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training:   9%|‚ñâ         | 15/164 [00:10<01:47,  1.39it/s, loss=0.1855, windows=2880, samples=960]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 64\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# ËÆ°ÁÆóÈ¢ÑÊµã\u001b[39;00m\n\u001b[0;32m     63\u001b[0m preds \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m---> 64\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     65\u001b[0m all_labels\u001b[38;5;241m.\u001b[39mextend(batch_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     67\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_uar = 0.0\n",
    "patience = 4\n",
    "patience_counter = 0\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "start_time = time.time()\n",
    "early_stop_counter = 0\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    print(f'\\n{\"=\"*80}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'{\"=\"*80}\\n')\n",
    "\n",
    "    total_windows = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")\n",
    "\n",
    "    for batch_data, batch_labels in progress_bar:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Ê£ÄÊü•Êï∞ÊçÆÂΩ¢Áä∂Âπ∂Â§ÑÁêÜ\n",
    "        if len(batch_data.shape) == 5:  # (batch_size, num_windows, 3, 128, 128)\n",
    "            batch_size, num_windows = batch_data.shape[:2]\n",
    "            \n",
    "            # ÈáçÂ°ë‰∏∫ (batch_size * num_windows, 3, 128, 128)\n",
    "            batch_data = batch_data.view(-1, 3, 128, 128)\n",
    "            batch_labels = batch_labels.view(-1)  # (batch_size * num_windows,)\n",
    "            \n",
    "            total_windows += batch_size * num_windows\n",
    "            total_samples += batch_size\n",
    "            \n",
    "        else:  # (batch_size, 3, 128, 128) - Âçï‰∏™windowÊÉÖÂÜµ\n",
    "            total_windows += batch_data.shape[0]\n",
    "            total_samples += batch_data.shape[0]\n",
    "\n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_data).squeeze()\n",
    "        \n",
    "        # Â§ÑÁêÜÂçïÊ†∑Êú¨ÊÉÖÂÜµ\n",
    "        if logits.dim() == 0:\n",
    "            logits = logits.unsqueeze(0)\n",
    "            \n",
    "        loss = criterion(logits, batch_labels.float())\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ËÆ°ÁÆóÈ¢ÑÊµã\n",
    "        preds = (torch.sigmoid(logits) > threshold).long()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'windows': f'{total_windows}',\n",
    "            'samples': f'{total_samples}'\n",
    "        })\n",
    "    \n",
    "    print(f\"Total windows processed in epoch {epoch+1}: {total_windows}\")\n",
    "    print(f\"Total samples processed in epoch {epoch+1}: {total_samples}\")\n",
    "    \n",
    "    if train_dataset.num_windows > 1:\n",
    "        print(f\"Average windows per sample: {total_windows/total_samples:.1f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(epoch_loss)\n",
    "    \n",
    "    train_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    train_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    # È™åËØÅÈò∂ÊÆµ - ‰ΩøÁî®votingËØÑ‰º∞\n",
    "    avg_val_loss, val_accuracy, val_f1, val_preds, val_labels = eval_with_voting(\n",
    "        model=model,\n",
    "        dataset=devel_dataset,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        threshold=threshold,\n",
    "        vote_mode='soft'\n",
    "    )\n",
    "\n",
    "    val_uar = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}] Summary:\")\n",
    "    print(f\"  üìà Training   - Loss: {epoch_loss:.4f}, ACCR: {train_accuracy:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"  üìä Validation - Loss: {avg_val_loss:.4f}, UAR: {val_uar:.4f}, F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # ËØ¶ÁªÜÁöÑÁ±ªÂà´Âè¨ÂõûÁéá\n",
    "    if len(set(val_labels)) > 1 and len(set(val_preds)) > 1:\n",
    "        class_recalls = recall_score(val_labels, val_preds, average=None, zero_division=0)\n",
    "        print(f\"  üéØ Class Recalls - Healthy: {class_recalls[0]:.4f}, Cold: {class_recalls[1]:.4f}\")\n",
    "\n",
    "    # ‰øùÂ≠òÊúÄ‰Ω≥Ê®°Âûã\n",
    "    if val_uar > best_uar:\n",
    "        best_uar = val_uar\n",
    "        early_stop_counter = 0\n",
    "        \n",
    "        # ‰øùÂ≠òÂÆåÊï¥ÁöÑÊ®°Âûã‰ø°ÊÅØ\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_uar': best_uar,\n",
    "            'train_loss': epoch_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'num_windows': train_dataset.num_windows\n",
    "        }, \"best_sliding_window.pth\")\n",
    "        \n",
    "        print(f\"üåü New best UAR: {best_uar:.4f}, saving model...\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"‚è≥ No improvement for {early_stop_counter}/{patience} epochs\")\n",
    "        \n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"‚ùå No improvement in UAR for {patience} epochs, early stopping...\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nüéâ Training complete in {(time.time() - start_time)/60:.2f} min\")\n",
    "print(f\"üèÜ Best Validation UAR: {best_uar:.4f}\")\n",
    "\n",
    "# ÊâìÂç∞ËÆ≠ÁªÉÁªüËÆ°‰ø°ÊÅØ\n",
    "if hasattr(train_dataset, 'num_windows'):\n",
    "    print(f\"üìä Training configuration:\")\n",
    "    print(f\"   - Windows per sample: {train_dataset.num_windows}\")\n",
    "    print(f\"   - Window size: {train_dataset.window_size}\")\n",
    "    print(f\"   - Stride: {train_dataset.stride}\")\n",
    "\n",
    "# ‰øùÂ≠òËÆ≠ÁªÉÂéÜÂè≤\n",
    "training_history = {\n",
    "    'training_losses': training_losses,\n",
    "    'validation_losses': validation_losses,\n",
    "    'best_uar': best_uar,\n",
    "    'num_epochs_trained': epoch + 1,\n",
    "    'early_stopped': early_stop_counter >= patience,\n",
    "    'num_windows': getattr(train_dataset, 'num_windows', 1)\n",
    "}\n",
    "\n",
    "torch.save(training_history, 'training_history.pth')\n",
    "print(f\"üíæ Training history saved to 'training_history.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29bff33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation UAR: 0.6368\n",
      "Class 0 (Healthy) Recall: 0.5971\n",
      "Class 1 (Cold) Recall: 0.6766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "uar = recall_score(val_labels, val_preds, average='macro')\n",
    "print(f\"Validation UAR: {uar:.4f}\")\n",
    "\n",
    "if len(set(val_labels)) > 1 and len(set(val_preds)) > 1:\n",
    "    class_recalls = recall_score(val_labels, val_preds, average=None)\n",
    "    print(f\"Class 0 (Healthy) Recall: {class_recalls[0]:.4f}\")\n",
    "    print(f\"Class 1 (Cold) Recall: {class_recalls[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
